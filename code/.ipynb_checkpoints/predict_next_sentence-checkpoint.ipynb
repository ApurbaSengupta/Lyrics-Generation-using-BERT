{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "colab_type": "code",
    "id": "KYHRcp62BLqS",
    "outputId": "cf796ec9-12ed-41c8-e336-6e8b61011b3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch_pretrained_bert in /usr/local/lib/python3.6/dist-packages (0.6.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.21.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.28.1)\n",
      "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.1.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2018.1.10)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.16.3)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.9.139)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2019.3.9)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.8)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.2)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.139 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.12.139)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.9.4)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.2.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.139->boto3->pytorch_pretrained_bert) (2.5.3)\n",
      "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.139->boto3->pytorch_pretrained_bert) (0.14)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.139->boto3->pytorch_pretrained_bert) (1.12.0)\n",
      "Requirement already satisfied: pronouncing in /usr/local/lib/python3.6/dist-packages (0.2.0)\n",
      "Requirement already satisfied: cmudict>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from pronouncing) (0.4.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_pretrained_bert\n",
    "!pip install pronouncing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ErYYr10CkeMc"
   },
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "model = BertForNextSentencePrediction.from_pretrained('bert-large-uncased')\n",
    "model.eval()\n",
    "\n",
    "sentence = '[CLS] Charles is a tailor [SEP] He is tall [SEP]'\n",
    "# sentence = '[CLS] Charles is a tailor [SEP] Excavation is important [SEP]'\n",
    "toks = tokenizer.tokenize(sentence)\n",
    "tok_ids = tokenizer.convert_tokens_to_ids(toks)\n",
    "tok_tensor = torch.LongTensor([tok_ids])\n",
    "token_type_ids_tensor = torch.LongTensor([[0, 0, 0, 0, 0, 0, 1, 1, 1, 1]])\n",
    "seq_relationship_logits = model(tok_tensor, token_type_ids_tensor)\n",
    "print(seq_relationship_logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yFE4Y9s9u0iV"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import torch\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertForNextSentencePrediction\n",
    "import pronouncing\n",
    "import re\n",
    "\n",
    "def predict_next_sentence(sentenceA, sentenceBs, tokenizer, model, rhyme=False):\n",
    "    seq_relationship_logits = get_next_sentence_logits(sentenceA, sentenceBs, tokenizer, model)\n",
    "    if rhyme:\n",
    "        for i, sentenceB in enumerate(sentenceBs):\n",
    "            last_word_A = re.sub(r'[^\\w]', '', sentenceA.split()[-1])\n",
    "            last_word_B = re.sub(r'[^\\w]', '', sentenceB.split()[-1])\n",
    "            if last_word_A in pronouncing.rhymes(last_word_B) or \\\n",
    "                last_word_B in pronouncing.rhymes(last_word_A):\n",
    "                print(f'{last_word_A} rhymes with {last_word_B}')\n",
    "                seq_relationship_logits[i, 0] += 10\n",
    "    return sentenceBs[seq_relationship_logits[:,0].argmax().tolist()]\n",
    "\n",
    "def get_ids_types_attention_from_sentence_pair(sentenceA, sentenceB, pad_total_size, tokenizer):\n",
    "    sentenceA_ids = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentenceA))\n",
    "    sentenceB_ids = tokenizer.convert_tokens_to_ids(tokenizer.tokenize(sentenceB))\n",
    "    padding_size = pad_total_size - len(sentenceA_ids) - len(sentenceB_ids)\n",
    "    sentence_ids = sentenceA_ids + sentenceB_ids + [0] * padding_size\n",
    "    sentence_types = [0] * len(sentenceA_ids) + [1] * len(sentenceB_ids) + [0] * padding_size\n",
    "    sentence_attention = [1] * (len(sentenceA_ids) + len(sentenceB_ids)) + [0] * padding_size\n",
    "    return sentence_ids, sentence_types, sentence_attention\n",
    "\n",
    "def reconstruct_song(lines, tokenizer, model):\n",
    "    pad_total_size = 2 * max(len(line) for line in lines)\n",
    "    for ordering in itertools.permutations(lines):\n",
    "        pair_ids, pair_types, pair_attentions = [], [], []        \n",
    "        for i in range(len(ordering) - 1):\n",
    "            pair_id, pair_type, pair_attention = \\\n",
    "                get_ids_types_attention_from_sentence_pair(ordering[i], ordering[i + 1], pad_total_size, tokenizer)\n",
    "            pair_ids.append(pair_id)\n",
    "            pair_types.append(pair_type)\n",
    "            pair_attentions.append(pair_attention)\n",
    "        ids_tensor = torch.LongTensor(pair_ids)\n",
    "        types_tensor = torch.LongTensor(pair_types)\n",
    "        attention_tensor = torch.LongTensor(pair_attentions)\n",
    "        seq_relationship_logits = model(ids_tensor, types_tensor, attention_tensor)\n",
    "#         print(seq_relationship_logits)\n",
    "#         print(sum(seq_relationship_logits[:, 0].tolist()))\n",
    "#         print(ordering)\n",
    "    \n",
    "    \n",
    "def get_next_sentence_logits(sentenceA, sentenceBs, tokenizer, model):\n",
    "    sentenceA_toks = tokenizer.tokenize(sentenceA)\n",
    "    sentenceA_ids = tokenizer.convert_tokens_to_ids(sentenceA_toks)\n",
    "    sentenceA_types = [0] * len(sentenceA_ids)\n",
    "    sentenceA_attention = [1] * len(sentenceA_ids)\n",
    "    tok_ids = []\n",
    "    tok_types = []\n",
    "    tok_attention = []\n",
    "    \n",
    "    sentenceBs_ids = []\n",
    "    for sentenceB in sentenceBs:\n",
    "        sentenceB_toks = tokenizer.tokenize(sentenceB)\n",
    "        sentenceB_ids = tokenizer.convert_tokens_to_ids(sentenceB_toks)\n",
    "        sentenceBs_ids.append(sentenceB_ids)\n",
    "        \n",
    "    max_sentenceB_length = max(len(sentenceB_ids) for sentenceB_ids in sentenceBs_ids)\n",
    "    for sentenceB_ids in sentenceBs_ids:\n",
    "        padding_size = max_sentenceB_length - len(sentenceB_ids)\n",
    "        padded_sentenceB_ids = sentenceB_ids + [0] * padding_size\n",
    "        padded_sentenceB_types = [1] * max_sentenceB_length\n",
    "        padded_sentenceB_attention = [1] * len(sentenceB_ids) + [0] * padding_size\n",
    "        tok_ids.append(sentenceA_ids + padded_sentenceB_ids)\n",
    "        tok_types.append(sentenceA_types + padded_sentenceB_types)\n",
    "        tok_attention.append(sentenceA_attention + padded_sentenceB_attention)\n",
    "    tok_ids_tensor = torch.LongTensor(tok_ids)\n",
    "    tok_types_tensor = torch.LongTensor(tok_types)\n",
    "    tok_attention_tensor = torch.LongTensor(tok_attention)\n",
    "    seq_relationship_logits = model(tok_ids_tensor, tok_types_tensor, tok_attention_tensor)\n",
    "    return seq_relationship_logits\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 9967
    },
    "colab_type": "code",
    "id": "UnGg7kPLvvr9",
    "outputId": "f5eb8247-e955-4a4e-a5a6-dcd384ae5a07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForNextSentencePrediction(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 1024, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 1024)\n",
       "      (token_type_embeddings): Embedding(2, 1024)\n",
       "      (LayerNorm): BertLayerNorm()\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (12): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (13): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (14): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (15): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (16): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (17): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (18): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (19): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (20): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (21): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (22): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "        (23): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "              (LayerNorm): BertLayerNorm()\n",
       "              (dropout): Dropout(p=0.1)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyNSPHead(\n",
       "    (seq_relationship): Linear(in_features=1024, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "model = BertForNextSentencePrediction.from_pretrained('bert-large-uncased')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8iwXmMgGvjK8",
    "outputId": "5b98ea30-0937-4299-e76b-31a79d8273cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He is very tall [SEP]\n"
     ]
    }
   ],
   "source": [
    "# Demonstration of predict_next_sentence\n",
    "predicted_sentence = predict_next_sentence('[CLS] Charles is a tailor [SEP]', ['He is green [SEP]', 'He is very tall [SEP]', 'Excavation is important [SEP]'], tokenizer, model)\n",
    "print(predicted_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yGA5uTQ6p6xo"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import argparse\n",
    "\n",
    "num_to_generate = 10\n",
    "num_options = 30\n",
    "\n",
    "def generate_predictions(args):\n",
    "    all_lines = []\n",
    "    all_pairs = []\n",
    "    with open(args.datafile, encoding='utf8') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            lines = row['lyrics'].split('\\n')\n",
    "            for i in range(len(lines) - 1):\n",
    "                all_pairs.append((lines[i], lines[i + 1]))\n",
    "                all_lines.append(lines[i])\n",
    "            all_lines.append(lines[len(lines) - 1])\n",
    "\n",
    "    sampled_data_x = {}\n",
    "    sampled_data_y = {}\n",
    "    correct_pairs = random.sample(all_pairs, num_to_generate)\n",
    "    for line1, line2 in correct_pairs:\n",
    "        sampled_data_y[line1] = line2\n",
    "        sampled_data_x[line1] = [line2]\n",
    "        sampled_data_x[line1].extend(random.sample(all_lines, num_options - 1))\n",
    "    \n",
    "    \n",
    "#     Batch make predictions to speed up runtime - crashes Colab for using too much RAM\n",
    "#\n",
    "#     all_sentence_ids, all_sentence_types, all_sentence_attentions = [], [], []\n",
    "#     for i, (line1, line2s) in enumerate(sampled_data_x.items()):\n",
    "#         sentenceA = line1\n",
    "#         for sentenceB in line2s:\n",
    "#             sentence_ids, sentence_types, sentence_attentions = \\\n",
    "#                 get_ids_types_attention_from_sentence_pair(sentenceA, sentenceB, 200, tokenizer)\n",
    "#             all_sentence_ids.append(sentence_ids)\n",
    "#             all_sentence_types.append(sentence_types)\n",
    "#             all_sentence_attentions.append(sentence_attentions)\n",
    "#     ids_tensor = torch.LongTensor(all_sentence_ids)\n",
    "#     types_tensor = torch.LongTensor(all_sentence_types)\n",
    "#     attention_tensor = torch.LongTensor(all_sentence_attentions)\n",
    "#     seq_relationship_logits = model(ids_tensor, types_tensor, attention_tensor)    \n",
    "#     predictions = []\n",
    "#     for i, (line1, line2s) in enumerate(sampled_data_x.items()):\n",
    "#         prediction_inx = seq_relationship_logits[i*num_options : (i + 1)*num_options, 0].argmax().tolist()\n",
    "#         predictions.append((line1, line2s[prediction_inx]))\n",
    "    \n",
    "\n",
    "    with open('predfile_norhyme', 'w') as file_norhyme:\n",
    "        with open('predfile_rhyme', 'w') as file_rhyme:\n",
    "            for i, (line1, line2s) in enumerate(sampled_data_x.items()):\n",
    "                line2 = predict_next_sentence(line1, line2s, tokenizer, model)\n",
    "                file_norhyme.write(f'{line1}\\t{line2}\\n')\n",
    "                line2 = predict_next_sentence(line1, line2s, tokenizer, model, rhyme=True)\n",
    "                file_rhyme.write(f'{line1}\\t{line2}\\n')\n",
    "                if (i + 1) % 10 == 0:\n",
    "                    print(f'Finished predicting {i + 1} lines...')\n",
    "    with open('goldfile', 'w') as file:\n",
    "        for line1, line2 in sampled_data_y.items():\n",
    "            file.write(f'{line1}\\t{line2}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jAbVQKO1OEa3"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import argparse\n",
    "\n",
    "def generate_predictions_one_song(args):\n",
    "    \n",
    "    num_songs = 10\n",
    "    \n",
    "    with open('goldfile', 'w') as file_gold:\n",
    "            with open('predfile_random_onesong', 'w') as file_random:\n",
    "                with open('predfile_norhyme_onesong', 'w') as file_norhyme:\n",
    "                    with open('predfile_rhyme_onesong', 'w') as file_rhyme:\n",
    "                        print('Deleting old files...')\n",
    "                        \n",
    "    for i in range(num_songs):\n",
    "        chosen_row = None\n",
    "        n = 1\n",
    "        with open(args.datafile, encoding='utf8') as csv_file:\n",
    "            csv_reader = csv.DictReader(csv_file)\n",
    "            for row in csv_reader:\n",
    "                if len(row['lyrics'].split('\\n')) > 20:\n",
    "                    continue\n",
    "                if random.random() < 1 / n:\n",
    "                    chosen_row = row\n",
    "                n += 1\n",
    "\n",
    "        lines = chosen_row['lyrics'].split('\\n')   \n",
    "\n",
    "        print(f\"Chosen Song: {chosen_row['song']}\")\n",
    "        print()\n",
    "        print('Lyrics:')\n",
    "        print('\\n'.join(lines))\n",
    "\n",
    "        sampled_data_x = {}\n",
    "        sampled_data_y = {}\n",
    "        for i in range(len(lines) - 1):\n",
    "            sampled_data_y[lines[i]] = lines[i + 1]\n",
    "            sampled_data_x[lines[i]] = list(set(line for line in lines if line != lines[i]))\n",
    "\n",
    "        with open('goldfile', 'a') as file_gold:\n",
    "            with open('predfile_random_onesong', 'a') as file_random:\n",
    "                with open('predfile_norhyme_onesong', 'a') as file_norhyme:\n",
    "                    with open('predfile_rhyme_onesong', 'a') as file_rhyme:\n",
    "                        for i, (line1, line2s) in enumerate(sampled_data_x.items()):\n",
    "                            line2 = sampled_data_y[line1]\n",
    "                            file_gold.write(f'{line1}\\t{line2}\\n')\n",
    "                            line2 = random.choice(line2s)\n",
    "                            file_random.write(f'{line1}\\t{line2}\\n')\n",
    "                            line2 = predict_next_sentence(line1, line2s, tokenizer, model)\n",
    "                            file_norhyme.write(f'{line1}\\t{line2}\\n')\n",
    "                            line2 = predict_next_sentence(line1, line2s, tokenizer, model, rhyme=True)\n",
    "                            file_rhyme.write(f'{line1}\\t{line2}\\n')\n",
    "#                             if (i + 1) % 10 == 0:\n",
    "#                                 print(f'Finished predicting {i + 1} lines...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D-zZNgiLkIih"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random            \n",
    "    \n",
    "def generate_song(args):\n",
    "    \n",
    "    num_lines = args.num_lines\n",
    "    num_choices = args.num_choices\n",
    "    \n",
    "    all_lines = []\n",
    "    with open(args.datafile, encoding='utf8') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        for row in csv_reader:\n",
    "            lines = row['lyrics'].split('\\n')\n",
    "            for i in range(len(lines)):\n",
    "                all_lines.append(lines[i])\n",
    "    \n",
    "    song_lines = [random.choice(all_lines)]\n",
    "    \n",
    "    for i in range(num_lines - 1):\n",
    "        lines = random.sample(all_lines, num_choices)\n",
    "        next_line = predict_next_sentence(song_lines[-1], lines, tokenizer, model, rhyme=True)\n",
    "        song_lines.append(next_line)\n",
    "\n",
    "    with open('generate_song3.txt', 'w') as file_song:\n",
    "        for line in song_lines:\n",
    "            file_song.write(f'{line}\\n')\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dm9fZF1iliPV"
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--datafile', type=str, required=True)\n",
    "parser.add_argument('--num-lines', type=int, required=True)\n",
    "parser.add_argument('--num-choices', type=int, required=True)\n",
    "args = parser.parse_args(['--datafile', 'english_rock.csv', '--num-lines', '10', '--num-choices', '1'])\n",
    "generate_song(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2feBIoxU9K-z"
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "def bleuScore(gold, pred):\n",
    "    cumulativeBlue, totalSentences = 0, len(gold)\n",
    "\n",
    "    for line in gold:\n",
    "        assert line in pred\n",
    "        reference = [gold[line].split(' ')]\n",
    "        candidate = pred[line].split(' ') \n",
    "        cumulativeBlue += sentence_bleu(reference, candidate, weights=(.334, 0.333, 0.333, 0))\n",
    "\n",
    "    return cumulativeBlue / totalSentences\n",
    "\n",
    "def accuracy(gold, pred):\n",
    "    num_correct, num_total = 0, 0\n",
    "    for line1 in gold:\n",
    "        assert line1 in pred\n",
    "        if gold[line1] == pred[line1]:\n",
    "            num_correct += 1\n",
    "        num_total += 1\n",
    "\n",
    "    accuracy = num_correct / num_total\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "def loadData(name):\n",
    "    data = {}\n",
    "    with open(name) as file:\n",
    "        for line in file:\n",
    "            line1, line2 = line.strip().split('\\t')\n",
    "            data[line1] = line2\n",
    "\n",
    "    return data\n",
    "\n",
    "def score_predictions(args):\n",
    "    gold = loadData(args.goldfile)\n",
    "    pred = loadData(args.predfile)\n",
    "\n",
    "    assert len(gold) == len(pred)\n",
    "\n",
    "    print(f'Accuracy: {accuracy(gold, pred):.2f}')\n",
    "    print(f'BLEU score: {bleuScore(gold, pred):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ezP-oUbv9XHv"
   },
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--datafile', type=str, required=True)\n",
    "args = parser.parse_args(['--datafile', 'train_rock.csv'])\n",
    "generate_predictions(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1300
    },
    "colab_type": "code",
    "id": "It3MaJr6PN8x",
    "outputId": "b78bd9f1-d479-465c-8710-3013f6d21976"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting old files...\n",
      "Chosen Song: dead-heat\n",
      "\n",
      "Lyrics:\n",
      "put them up against the wall\n",
      "pull the trigger watch them fall\n",
      "they can only feel the pain\n",
      "stand them up and start again\n",
      "tell the sargeant what you saw\n",
      "fear the long arm of the law\n",
      "even though it's hanging there\n",
      "drugs and bad guys you'd better beware\n",
      "of dead heat they're dead heat\n",
      "if you shoot 'em down they'll be back on thier feet\n",
      "they're dead heat they're dead heat\n",
      "if you shoot 'em down they'll be back on the street\n",
      "take 'em down contempt divine (?)\n",
      "a cat that looks like frankenstein\n",
      "he's holding up a jewellery store\n",
      "listen to his bullets roar\n",
      "their job is done they're all alone\n",
      "they work their fingers to the bone\n",
      "they're weary as they walk their beat\n",
      "all day long they're dead on their feet\n",
      "they're dead heat they're dead heat\n",
      "certified zombies from their head to their feet\n",
      "they're dead heat they're dead heat\n",
      "if you shoot 'em down they'll be back on thier feet\n",
      "wall rhymes with fall\n",
      "fall rhymes with wall\n",
      "pain rhymes with again\n",
      "again rhymes with pain\n",
      "saw rhymes with law\n",
      "law rhymes with saw\n",
      "there rhymes with beware\n",
      "beware rhymes with there\n",
      "heat rhymes with street\n",
      "heat rhymes with feet\n",
      "heat rhymes with feet\n",
      "heat rhymes with feet\n",
      "heat rhymes with beat\n",
      "feet rhymes with street\n",
      "feet rhymes with heat\n",
      "feet rhymes with heat\n",
      "feet rhymes with beat\n",
      "heat rhymes with street\n",
      "heat rhymes with feet\n",
      "heat rhymes with feet\n",
      "heat rhymes with feet\n",
      "heat rhymes with beat\n",
      "street rhymes with heat\n",
      "street rhymes with feet\n",
      "street rhymes with heat\n",
      "street rhymes with feet\n",
      "street rhymes with feet\n",
      "street rhymes with beat\n",
      "store rhymes with roar\n",
      "roar rhymes with store\n",
      "alone rhymes with bone\n",
      "bone rhymes with alone\n",
      "beat rhymes with street\n",
      "beat rhymes with heat\n",
      "beat rhymes with heat\n",
      "beat rhymes with feet\n",
      "beat rhymes with feet\n",
      "beat rhymes with feet\n",
      "feet rhymes with street\n",
      "feet rhymes with heat\n",
      "feet rhymes with heat\n",
      "feet rhymes with beat\n",
      "feet rhymes with street\n",
      "feet rhymes with heat\n",
      "feet rhymes with heat\n",
      "feet rhymes with beat\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--datafile', type=str, required=True)\n",
    "args = parser.parse_args(['--datafile', 'train_rock.csv'])\n",
    "generate_predictions_one_song(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "lf_SKbfrT_is",
    "outputId": "138d8ab1-b375-4c74-fa33-bb6ffed04593"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.10\n",
      "BLEU score: 0.22\n",
      "Accuracy: 0.05\n",
      "BLEU score: 0.12\n",
      "Accuracy: 0.38\n",
      "BLEU score: 0.56\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--goldfile', type=str, required=True)\n",
    "parser.add_argument('--predfile', type=str, required=True)\n",
    "args = parser.parse_args(['--goldfile', 'goldfile', '--predfile', 'predfile_random_onesong'])\n",
    "score_predictions(args)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--goldfile', type=str, required=True)\n",
    "parser.add_argument('--predfile', type=str, required=True)\n",
    "args = parser.parse_args(['--goldfile', 'goldfile', '--predfile', 'predfile_norhyme_onesong'])\n",
    "score_predictions(args)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--goldfile', type=str, required=True)\n",
    "parser.add_argument('--predfile', type=str, required=True)\n",
    "args = parser.parse_args(['--goldfile', 'goldfile', '--predfile', 'predfile_rhyme_onesong'])\n",
    "score_predictions(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "id": "0KXs_4yz9RjL",
    "outputId": "d2cf514b-e4b2-428f-860b-2fd4bcd7c6dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00\n",
      "BLEU score: 0.15\n",
      "Accuracy: 0.00\n",
      "BLEU score: 0.15\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--goldfile', type=str, required=True)\n",
    "parser.add_argument('--predfile', type=str, required=True)\n",
    "args = parser.parse_args(['--goldfile', 'goldfile', '--predfile', 'predfile_norhyme'])\n",
    "score_predictions(args)\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--goldfile', type=str, required=True)\n",
    "parser.add_argument('--predfile', type=str, required=True)\n",
    "args = parser.parse_args(['--goldfile', 'goldfile', '--predfile', 'predfile_rhyme'])\n",
    "score_predictions(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 8434
    },
    "colab_type": "code",
    "id": "zc6gw-GC1RK-",
    "outputId": "448bf3ea-2237-416a-faf6-58590ee1aca6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Song: you-re-cracked Prob of rhyme: 0.5\n",
      "Song: everybody-makes-me-barf Prob of rhyme: 0.6\n",
      "Song: goodbye Prob of rhyme: 0.3333333333333333\n",
      "Song: perfect-ten Prob of rhyme: 0.44\n",
      "Song: don-t-wait Prob of rhyme: 0.3225806451612903\n",
      "Song: paper-thin-hotel Prob of rhyme: 0.38461538461538464\n",
      "Song: candy-came-back Prob of rhyme: 0.3333333333333333\n",
      "Song: nostradamus Prob of rhyme: 0.375\n",
      "Song: shah-of-shahs Prob of rhyme: 0.32142857142857145\n",
      "Song: cleave-to-me Prob of rhyme: 0.3684210526315789\n",
      "Song: you-give-love-a-bad-name Prob of rhyme: 0.34782608695652173\n",
      "Song: heart-of-a-bad-machine Prob of rhyme: 0.36363636363636365\n",
      "Song: automatic-thrill Prob of rhyme: 0.30952380952380953\n",
      "Song: dog-day-dog-night Prob of rhyme: 0.45714285714285713\n",
      "Song: lord-of-the-dusk Prob of rhyme: 0.36363636363636365\n",
      "Song: little-man Prob of rhyme: 0.3125\n",
      "Song: conniption-fit Prob of rhyme: 0.3076923076923077\n",
      "Song: you-shout-you-shout-you-shout-you-shout Prob of rhyme: 0.3170731707317073\n",
      "Song: mine-tonite Prob of rhyme: 0.30434782608695654\n",
      "Song: hand-me-downs Prob of rhyme: 0.45714285714285713\n",
      "Song: can-t-get-next-to-you Prob of rhyme: 0.3333333333333333\n",
      "Song: love-is-the-hero Prob of rhyme: 0.35714285714285715\n",
      "Song: reach-for-the-sky Prob of rhyme: 0.35135135135135137\n",
      "Song: gather Prob of rhyme: 0.37142857142857144\n",
      "Song: sex-appeal Prob of rhyme: 0.37037037037037035\n",
      "Song: cry Prob of rhyme: 0.38461538461538464\n",
      "Song: strange-days Prob of rhyme: 0.42857142857142855\n",
      "Song: milking Prob of rhyme: 0.3333333333333333\n",
      "Song: holy-night-fever Prob of rhyme: 0.6666666666666666\n",
      "Song: heart-failure Prob of rhyme: 0.6363636363636364\n",
      "Song: re-make-re-model Prob of rhyme: 0.3333333333333333\n",
      "Song: all-along-the-watchtower Prob of rhyme: 0.3333333333333333\n",
      "Song: simple-twist-of-fate Prob of rhyme: 0.375\n",
      "Song: tender-is-the-night Prob of rhyme: 0.3157894736842105\n",
      "Song: smoke-gets-in-your-eyes Prob of rhyme: 0.3157894736842105\n",
      "Song: i-ll-see-you-again Prob of rhyme: 0.3333333333333333\n",
      "Song: just-one-of-those-things Prob of rhyme: 0.375\n",
      "Song: you-go-to-my-head Prob of rhyme: 0.3333333333333333\n",
      "Song: as-time-goes-by Prob of rhyme: 0.375\n",
      "Song: your-sweet-eyes Prob of rhyme: 0.30303030303030304\n",
      "Song: alone-with-you Prob of rhyme: 0.375\n",
      "Song: spring-69 Prob of rhyme: 0.4375\n",
      "Song: dead-heat Prob of rhyme: 0.5416666666666666\n",
      "Song: my-pop-the-cop Prob of rhyme: 0.3125\n",
      "Song: i-m-stuck-in-a-pagoda-with-tricia-toyota Prob of rhyme: 0.32\n",
      "Song: silent-night Prob of rhyme: 0.3333333333333333\n",
      "Song: eve-of-destruction Prob of rhyme: 0.36666666666666664\n",
      "Song: got-it-at-the-store Prob of rhyme: 0.7\n",
      "Song: hideous Prob of rhyme: 0.3125\n",
      "Song: you-don-t-have-to-go Prob of rhyme: 0.3125\n",
      "Song: blinded-by-the-light-live Prob of rhyme: 0.32608695652173914\n",
      "Song: erie-canal-live Prob of rhyme: 0.30434782608695654\n",
      "Song: rabbits Prob of rhyme: 0.5714285714285714\n",
      "Song: one-of-us-cannot-be-wrong Prob of rhyme: 0.35294117647058826\n",
      "Song: sisters-of-mercy Prob of rhyme: 0.47058823529411764\n",
      "Song: everybody-knows Prob of rhyme: 0.3125\n",
      "Song: paper-thin-hotel Prob of rhyme: 0.42857142857142855\n",
      "Song: i-d-rather-be-gone Prob of rhyme: 0.375\n",
      "Song: you-done-lost-your-baby Prob of rhyme: 0.3333333333333333\n",
      "Song: kaw-liga Prob of rhyme: 0.3333333333333333\n",
      "Song: we-re-caught-between-a-love-and-a-love-affair Prob of rhyme: 0.3076923076923077\n",
      "Song: my-heart-won-t-listen-to-my-mind Prob of rhyme: 0.3076923076923077\n",
      "Song: i-just-wanted-you-to-know Prob of rhyme: 0.5714285714285714\n",
      "Song: clown Prob of rhyme: 0.4375\n",
      "Song: just-like-a-stranger Prob of rhyme: 0.38461538461538464\n",
      "Song: don-t-tell-me-you-re-sorry Prob of rhyme: 0.3125\n",
      "Song: go-woman-go Prob of rhyme: 0.46153846153846156\n",
      "Song: we-ve-closed-our-eyes-to-shame Prob of rhyme: 0.5\n",
      "Song: window-up-above Prob of rhyme: 0.35714285714285715\n",
      "Song: i-ve-never-loved-you-more Prob of rhyme: 0.5833333333333334\n",
      "Song: i-d-love-to-lay-you-down Prob of rhyme: 0.4375\n",
      "Song: i-ll-come-running Prob of rhyme: 0.45454545454545453\n",
      "Song: born-to-lose Prob of rhyme: 0.6\n",
      "Song: the-third-man Prob of rhyme: 0.391304347826087\n",
      "Song: don-t-cry-joni Prob of rhyme: 0.425\n",
      "Song: she-takes-care-of-me Prob of rhyme: 0.3333333333333333\n",
      "Song: another-man-s-woman Prob of rhyme: 0.3333333333333333\n",
      "Song: slowly Prob of rhyme: 0.4444444444444444\n",
      "Song: i-love-you-more-in-memory Prob of rhyme: 0.3076923076923077\n",
      "Song: i-m-used-to-losing-you Prob of rhyme: 0.4166666666666667\n",
      "Song: i-ll-share-my-world-with-you Prob of rhyme: 0.46153846153846156\n",
      "Song: let-it-ring Prob of rhyme: 0.38461538461538464\n",
      "Song: our-conscience-you-and-me Prob of rhyme: 0.38461538461538464\n",
      "Song: i-never-did-quite-get-over-you Prob of rhyme: 0.5714285714285714\n",
      "Song: i-didn-t-lose-her-i-threw-her-away Prob of rhyme: 0.5\n",
      "Song: before-i-ll-set-her-free Prob of rhyme: 0.35294117647058826\n",
      "Song: you-make-it-hard-to-take-the-easy-way-out Prob of rhyme: 0.3333333333333333\n",
      "Song: i-still-see-him-through-the-hurt-in-your-eyes Prob of rhyme: 0.3076923076923077\n",
      "Song: leona Prob of rhyme: 0.4375\n",
      "Song: don-t-let-it-go-to-your-heart Prob of rhyme: 0.3125\n",
      "Song: never-ending-song-of-love Prob of rhyme: 0.375\n",
      "Song: joy-to-the-world Prob of rhyme: 0.3333333333333333\n",
      "Song: lost-in-the-feeling Prob of rhyme: 0.3333333333333333\n",
      "Song: joanie Prob of rhyme: 0.32432432432432434\n",
      "Song: we-ve-been-strong-long-enough Prob of rhyme: 0.4375\n",
      "Song: somebody-s-needin-somebody Prob of rhyme: 0.36363636363636365\n",
      "Song: heart-s-breakin-all-over-town Prob of rhyme: 0.3076923076923077\n",
      "Song: bender Prob of rhyme: 0.3125\n",
      "Song: what-s-left Prob of rhyme: 0.3695652173913043\n",
      "Song: on-my-own Prob of rhyme: 0.3125\n",
      "Song: always Prob of rhyme: 0.3076923076923077\n",
      "Song: the-answer-s-at-the-end Prob of rhyme: 0.3333333333333333\n",
      "Song: something Prob of rhyme: 0.3157894736842105\n",
      "Song: end-of-the-line Prob of rhyme: 0.40625\n",
      "Song: for-you-blue Prob of rhyme: 0.5833333333333334\n",
      "Song: my-back-pages Prob of rhyme: 0.3333333333333333\n",
      "Song: never-get-over-you Prob of rhyme: 0.30434782608695654\n",
      "Song: congratulations Prob of rhyme: 0.38095238095238093\n",
      "Song: ooh-baby Prob of rhyme: 0.4444444444444444\n",
      "Song: not-alone-anymore Prob of rhyme: 0.3333333333333333\n",
      "Song: spaceman Prob of rhyme: 0.38461538461538464\n",
      "Song: some-of-shelley-s-blues Prob of rhyme: 0.35\n",
      "Song: them-vs-you-vs-me Prob of rhyme: 0.35294117647058826\n",
      "Song: stone-soul Prob of rhyme: 0.3333333333333333\n",
      "Song: break-down-doors Prob of rhyme: 0.36\n",
      "Song: without-you Prob of rhyme: 0.4\n",
      "Song: i-hear-you-knocking Prob of rhyme: 0.3125\n",
      "Song: walking-blues Prob of rhyme: 0.4166666666666667\n",
      "Song: she-s-so-happy-to-be Prob of rhyme: 0.3157894736842105\n",
      "Song: king-of-pain Prob of rhyme: 0.38235294117647056\n",
      "Song: too-hot Prob of rhyme: 0.3018867924528302\n",
      "Song: so-what Prob of rhyme: 0.38181818181818183\n",
      "Song: have-a-nice-day Prob of rhyme: 0.3333333333333333\n",
      "Song: reality-whitewash Prob of rhyme: 0.3673469387755102\n",
      "Song: peace-of-mind Prob of rhyme: 0.4482758620689655\n",
      "Song: million-dollar-loan Prob of rhyme: 0.5\n",
      "Song: you-ve-haunted-me-all-my-life Prob of rhyme: 0.36\n",
      "Song: heartbreak-hotel Prob of rhyme: 0.3076923076923077\n",
      "Song: in-a-sentimental-mood Prob of rhyme: 0.375\n",
      "Song: you-look-so-good-to-me Prob of rhyme: 0.6666666666666666\n",
      "Song: mortal Prob of rhyme: 0.3333333333333333\n",
      "Song: pain Prob of rhyme: 0.36363636363636365\n",
      "Song: whitey-s-revenge-the-eminem-diss Prob of rhyme: 0.3230769230769231\n",
      "Song: i-get-by Prob of rhyme: 0.3150684931506849\n",
      "Song: today-watch-me-shine Prob of rhyme: 0.36585365853658536\n",
      "Song: lonely-road Prob of rhyme: 0.3235294117647059\n",
      "Song: the-white-boy-is-back Prob of rhyme: 0.3333333333333333\n",
      "Song: blinded-by-the-sun Prob of rhyme: 0.42424242424242425\n",
      "Song: 2-pieces-of-drama Prob of rhyme: 0.3181818181818182\n",
      "Song: die-in-yer-arms Prob of rhyme: 0.3333333333333333\n",
      "Song: acrylic Prob of rhyme: 0.3404255319148936\n",
      "Song: newport-party Prob of rhyme: 0.36363636363636365\n",
      "Song: don-t-hold-your-breath Prob of rhyme: 0.5\n",
      "Song: barbara-jean-a-christmas-song Prob of rhyme: 0.375\n",
      "Song: close-yet-far Prob of rhyme: 0.3333333333333333\n",
      "Song: opening-night Prob of rhyme: 0.3055555555555556\n",
      "Song: let-go Prob of rhyme: 0.38461538461538464\n",
      "Song: shallow-bay Prob of rhyme: 0.46774193548387094\n",
      "Song: in-india-you Prob of rhyme: 0.4\n",
      "Song: heaven-s-wall Prob of rhyme: 0.4375\n",
      "Song: in-the-deepest-of-waters Prob of rhyme: 0.34615384615384615\n",
      "Song: unconscience Prob of rhyme: 0.375\n",
      "Song: pay-me-a-dollar Prob of rhyme: 0.36\n",
      "Song: tumbling-tumbleweed Prob of rhyme: 0.45\n",
      "Song: if-i-was-a-doo-doo-doo Prob of rhyme: 0.6666666666666666\n",
      "Song: i-luv-u-bailey-jay Prob of rhyme: 0.3055555555555556\n",
      "Song: damaged-soul Prob of rhyme: 0.375\n",
      "Song: disturbing-the-priest Prob of rhyme: 0.5416666666666666\n",
      "Song: hot-line Prob of rhyme: 0.5\n",
      "Song: solitude Prob of rhyme: 0.3076923076923077\n",
      "Song: supernaut Prob of rhyme: 0.3333333333333333\n",
      "Song: sleeping-village Prob of rhyme: 0.5\n",
      "Song: symptom-of-the-univers Prob of rhyme: 0.375\n",
      "Song: the-wizard Prob of rhyme: 0.3333333333333333\n",
      "Song: let-it-ride Prob of rhyme: 0.375\n",
      "Song: true-colors Prob of rhyme: 0.3333333333333333\n",
      "Song: coming-home Prob of rhyme: 0.3333333333333333\n",
      "Song: second-wind Prob of rhyme: 0.3793103448275862\n",
      "Song: love-s-got-me-doin-time Prob of rhyme: 0.34146341463414637\n",
      "Song: biz Prob of rhyme: 0.4166666666666667\n",
      "Song: you-came-walking Prob of rhyme: 0.38461538461538464\n",
      "Song: i-ain-t-hiding Prob of rhyme: 0.3333333333333333\n",
      "Song: time-will-tell Prob of rhyme: 0.3448275862068966\n",
      "Song: garden-state Prob of rhyme: 0.3611111111111111\n",
      "Song: diamond-ring Prob of rhyme: 0.35294117647058826\n",
      "Song: oh-well Prob of rhyme: 0.4\n",
      "Song: when-mermaids-cry Prob of rhyme: 0.3157894736842105\n",
      "Song: save-tonight Prob of rhyme: 0.3695652173913043\n",
      "Song: flathead Prob of rhyme: 0.46153846153846156\n",
      "Song: creepin-up-the-backstairs Prob of rhyme: 0.40425531914893614\n",
      "Song: baby-fratelli Prob of rhyme: 0.35\n",
      "Song: vince-the-loveable-stoner Prob of rhyme: 0.3076923076923077\n",
      "Song: my-friend-john Prob of rhyme: 0.3333333333333333\n",
      "Song: why Prob of rhyme: 0.42857142857142855\n",
      "Song: in-the-land-of-grey-and-pink Prob of rhyme: 0.3333333333333333\n",
      "Song: house-built-for-two Prob of rhyme: 0.3137254901960784\n",
      "Song: break-your-frame Prob of rhyme: 0.36363636363636365\n",
      "Song: nowaday-s-clancy-can-t-even-sing Prob of rhyme: 0.3125\n",
      "Song: pay-the-price Prob of rhyme: 0.35294117647058826\n",
      "Song: everybody-s-wrong Prob of rhyme: 0.38461538461538464\n",
      "Song: the-way-dreams-are Prob of rhyme: 0.42105263157894735\n",
      "Song: every-little-thing Prob of rhyme: 0.3157894736842105\n",
      "Song: set-me-free Prob of rhyme: 0.3235294117647059\n",
      "Song: u-minus-cool Prob of rhyme: 0.40625\n",
      "Song: in-life-my-friends Prob of rhyme: 0.3953488372093023\n",
      "Song: turn-to-gold Prob of rhyme: 0.3076923076923077\n",
      "Song: here-goes Prob of rhyme: 0.37037037037037035\n",
      "Song: you-are-always-on-my-mind Prob of rhyme: 0.34375\n",
      "Song: rip-off Prob of rhyme: 0.30434782608695654\n",
      "Song: hong-kong-fury Prob of rhyme: 0.3333333333333333\n",
      "Song: don-t-come-knocking Prob of rhyme: 0.42857142857142855\n",
      "Song: bullets Prob of rhyme: 0.32\n",
      "Song: round-round Prob of rhyme: 0.3125\n",
      "Song: metal-steel Prob of rhyme: 0.47058823529411764\n",
      "Song: spacesuit Prob of rhyme: 0.3125\n",
      "Song: medicine Prob of rhyme: 0.3333333333333333\n",
      "Song: the-best-laid-plans Prob of rhyme: 0.5\n",
      "Song: good-day-for-dying Prob of rhyme: 0.3333333333333333\n",
      "Song: even-if-you-know-me Prob of rhyme: 0.3333333333333333\n",
      "Song: smart-in-a-stupid-way Prob of rhyme: 0.5172413793103449\n",
      "Song: with-you-in-a-heartbeat Prob of rhyme: 0.4782608695652174\n",
      "Song: don-t-let-me-down Prob of rhyme: 0.3333333333333333\n",
      "Song: 100-miles Prob of rhyme: 0.42857142857142855\n",
      "Song: love-so-strong Prob of rhyme: 0.35555555555555557\n",
      "Song: honey-child Prob of rhyme: 0.5882352941176471\n",
      "Song: electric-land Prob of rhyme: 0.4\n",
      "Song: hello-mabel Prob of rhyme: 0.30434782608695654\n",
      "Song: cereal-wars Prob of rhyme: 0.3125\n",
      "Song: triple-zero Prob of rhyme: 0.3235294117647059\n",
      "Song: blind Prob of rhyme: 0.42105263157894735\n",
      "Song: some-kind-of-love-song Prob of rhyme: 0.4482758620689655\n",
      "Song: a-regular-guy Prob of rhyme: 0.4166666666666667\n",
      "Song: taste-my-fist Prob of rhyme: 0.42857142857142855\n",
      "Song: the-shrine Prob of rhyme: 0.325\n",
      "Song: montreal Prob of rhyme: 0.3333333333333333\n",
      "Song: lost-in-the-light Prob of rhyme: 0.36363636363636365\n",
      "Song: all-i-ve-ever-known Prob of rhyme: 0.375\n",
      "Song: waves Prob of rhyme: 0.5454545454545454\n",
      "Song: slave Prob of rhyme: 0.3333333333333333\n",
      "Song: give-myself-to-you Prob of rhyme: 0.3170731707317073\n",
      "Song: count-your-blessings Prob of rhyme: 0.375\n",
      "Song: saturday-night-is-the-loneliness-night-in-the-week Prob of rhyme: 0.3684210526315789\n",
      "Song: you-could-show-me Prob of rhyme: 0.3333333333333333\n",
      "Song: love-is-here-to-stay Prob of rhyme: 0.4166666666666667\n",
      "Song: nevertheless Prob of rhyme: 0.35294117647058826\n",
      "Song: some-girls Prob of rhyme: 0.4642857142857143\n",
      "Song: ships Prob of rhyme: 0.48148148148148145\n",
      "Song: bandstand-boogie Prob of rhyme: 0.38461538461538464\n",
      "Song: white-christmas Prob of rhyme: 0.3333333333333333\n",
      "Song: alone-together Prob of rhyme: 0.36\n",
      "Song: the-music-of-the-night Prob of rhyme: 0.35294117647058826\n",
      "Song: chicken-soup-with-rice Prob of rhyme: 0.44776119402985076\n",
      "Song: friday-s-tie-dye-nightmare Prob of rhyme: 0.3333333333333333\n",
      "Song: crying-in-the-rain Prob of rhyme: 0.30434782608695654\n",
      "Song: still-here-thinking-of-you Prob of rhyme: 0.3333333333333333\n",
      "Song: time-alone Prob of rhyme: 0.5333333333333333\n",
      "Song: crying-shame Prob of rhyme: 0.3225806451612903\n",
      "Song: disillusion Prob of rhyme: 0.3333333333333333\n",
      "Song: when-the-river-runs-dry Prob of rhyme: 0.3125\n",
      "Song: i-ll-just-remember-you Prob of rhyme: 0.4666666666666667\n",
      "Song: moonglow Prob of rhyme: 0.3125\n",
      "Song: alone-together Prob of rhyme: 0.3333333333333333\n",
      "Song: spring-will-be-a-little-late-this-year Prob of rhyme: 0.36363636363636365\n",
      "Song: my-romance Prob of rhyme: 0.3333333333333333\n",
      "Song: you-won-t-forget-me Prob of rhyme: 0.36363636363636365\n",
      "Song: time-after-time Prob of rhyme: 0.3333333333333333\n",
      "Song: the-garden Prob of rhyme: 0.46153846153846156\n",
      "Song: come-back-home Prob of rhyme: 0.3684210526315789\n",
      "Song: one-love-stand Prob of rhyme: 0.3333333333333333\n",
      "Song: such-a-good-boy Prob of rhyme: 0.30952380952380953\n",
      "Song: hurt Prob of rhyme: 0.375\n",
      "Song: black-and-white Prob of rhyme: 0.3488372093023256\n",
      "Song: late-for-the-sky Prob of rhyme: 0.4\n",
      "Song: amylase Prob of rhyme: 0.3684210526315789\n",
      "Song: donald-where-s-yer-trousers Prob of rhyme: 0.358974358974359\n",
      "Song: look-at-that-look-at-that Prob of rhyme: 0.45454545454545453\n",
      "Song: jw-construction Prob of rhyme: 0.75\n",
      "Song: a-passed-life Prob of rhyme: 0.3888888888888889\n",
      "Song: died-with-you Prob of rhyme: 0.36666666666666664\n",
      "Song: summer-holiday Prob of rhyme: 0.3225806451612903\n",
      "Song: ring-of-fire Prob of rhyme: 0.5\n",
      "Song: she-s-not-you Prob of rhyme: 0.5\n",
      "Song: can-t-help-falling-in-love Prob of rhyme: 0.3076923076923077\n",
      "Song: i-walk-the-line Prob of rhyme: 0.375\n",
      "Song: my-happiness Prob of rhyme: 0.5\n",
      "Song: smile-more Prob of rhyme: 0.40476190476190477\n",
      "Song: days-of-wine-roses Prob of rhyme: 0.3125\n",
      "Song: year-of-the-pig Prob of rhyme: 0.3181818181818182\n",
      "Song: generation Prob of rhyme: 0.5\n",
      "Song: liar-liar Prob of rhyme: 0.5\n",
      "Song: cassandra Prob of rhyme: 0.30303030303030304\n",
      "Song: when-a-child-is-born Prob of rhyme: 0.4375\n",
      "Song: that-ll-be-the-day Prob of rhyme: 0.375\n",
      "Song: nothin-i-won-t-do Prob of rhyme: 0.41379310344827586\n",
      "Song: choo-choo-ch-boogie Prob of rhyme: 0.3333333333333333\n",
      "Song: highway-killing-me Prob of rhyme: 0.6153846153846154\n",
      "Song: leavin-again-again Prob of rhyme: 0.4166666666666667\n",
      "Song: mr-important Prob of rhyme: 0.4375\n",
      "Song: making-people-normal Prob of rhyme: 0.375\n",
      "Song: conspiracy-a-go-go Prob of rhyme: 0.4375\n",
      "Song: teen-c-power Prob of rhyme: 0.3125\n",
      "Song: teen-c-power Prob of rhyme: 0.30303030303030304\n",
      "Song: and-i Prob of rhyme: 0.42857142857142855\n",
      "Song: ride-across-the-river Prob of rhyme: 0.4444444444444444\n",
      "Song: six-blade-knife Prob of rhyme: 0.35294117647058826\n",
      "Song: water-of-love Prob of rhyme: 0.35\n",
      "Song: angel-of-mercy Prob of rhyme: 0.34782608695652173\n",
      "Song: time-is-ticking-away Prob of rhyme: 0.3181818181818182\n",
      "Song: schizo Prob of rhyme: 0.4\n",
      "Song: watch-me-play Prob of rhyme: 0.3684210526315789\n",
      "Song: sex-will-keep-us-together Prob of rhyme: 0.3157894736842105\n",
      "Song: bullet-4-56 Prob of rhyme: 0.42857142857142855\n",
      "Song: guillotine-day Prob of rhyme: 0.42857142857142855\n",
      "Song: heart-of-steel Prob of rhyme: 0.35714285714285715\n",
      "Song: gonna-get-you Prob of rhyme: 0.5454545454545454\n",
      "Song: sweet-obsession Prob of rhyme: 0.6451612903225806\n",
      "Song: i-walk-the-wall Prob of rhyme: 0.43478260869565216\n",
      "Song: chance Prob of rhyme: 0.4230769230769231\n",
      "Song: what-are-you-working-for Prob of rhyme: 0.4230769230769231\n",
      "Song: we-re-not-in-kansas Prob of rhyme: 0.3170731707317073\n",
      "Song: oh-well Prob of rhyme: 0.4\n",
      "Song: the-teacher Prob of rhyme: 0.38461538461538464\n",
      "Song: president-slipped-and-fell Prob of rhyme: 0.36666666666666664\n",
      "Song: the-one-i-love Prob of rhyme: 0.475\n",
      "Song: driving-to-damascus Prob of rhyme: 0.5\n",
      "Song: message-of-love Prob of rhyme: 0.38461538461538464\n",
      "Song: fields-of-fire Prob of rhyme: 0.4375\n",
      "Song: heart-of-the-world Prob of rhyme: 0.5128205128205128\n",
      "Song: beat-the-devil Prob of rhyme: 0.48484848484848486\n",
      "Song: close-action Prob of rhyme: 0.42857142857142855\n",
      "Song: golden-age Prob of rhyme: 0.3333333333333333\n",
      "Song: i-wouldn-t-want-to-be-like-you Prob of rhyme: 0.38095238095238093\n",
      "Song: nothing-left-to-lose Prob of rhyme: 0.3333333333333333\n",
      "Song: damned-if-i-do Prob of rhyme: 0.5\n",
      "Song: the-halves-that-make-us-whole Prob of rhyme: 0.375\n",
      "Song: call-it-in-the-air Prob of rhyme: 0.3611111111111111\n",
      "Song: phantom-treasure Prob of rhyme: 0.4166666666666667\n",
      "Song: hammer-in-a-shell Prob of rhyme: 0.3103448275862069\n",
      "Song: all-hands-against-his-own Prob of rhyme: 0.35714285714285715\n",
      "Song: girl-is-on-my-mind Prob of rhyme: 0.5\n",
      "Song: strange-desire Prob of rhyme: 0.4166666666666667\n",
      "Song: run-me-down Prob of rhyme: 0.3333333333333333\n",
      "Song: i-cry-alone Prob of rhyme: 0.5333333333333333\n",
      "Song: same-old-thing Prob of rhyme: 0.3888888888888889\n",
      "Song: things-ain-t-like-they-used-to-be Prob of rhyme: 0.39285714285714285\n",
      "Song: lies Prob of rhyme: 0.3888888888888889\n",
      "Song: things-aren-t-like-they-used-to-be Prob of rhyme: 0.39285714285714285\n",
      "Song: turn-blue Prob of rhyme: 0.625\n",
      "Song: for-now Prob of rhyme: 0.3170731707317073\n",
      "Song: sugar Prob of rhyme: 0.36363636363636365\n",
      "Song: alameda Prob of rhyme: 0.375\n",
      "Song: sorry-my-mistake Prob of rhyme: 0.3333333333333333\n",
      "Song: somebody-that-i-used-to-know Prob of rhyme: 0.4375\n",
      "Song: baby-britain Prob of rhyme: 0.3488372093023256\n",
      "Song: no-name-no-5 Prob of rhyme: 0.4166666666666667\n",
      "Song: speed-trials Prob of rhyme: 0.35\n",
      "Song: standing-alone Prob of rhyme: 0.3111111111111111\n",
      "Song: this-too-shall-pass Prob of rhyme: 0.3055555555555556\n",
      "Song: sneaking-up-on-boo-radley Prob of rhyme: 0.3235294117647059\n",
      "Song: swan-song Prob of rhyme: 0.34146341463414637\n",
      "Song: i-will-walk-with-you Prob of rhyme: 0.3611111111111111\n",
      "Song: china-doll Prob of rhyme: 0.4583333333333333\n",
      "Song: cyclone Prob of rhyme: 0.3888888888888889\n",
      "Song: take-out-the-trash Prob of rhyme: 0.3148148148148148\n",
      "Song: bang-bang Prob of rhyme: 0.34615384615384615\n",
      "Song: contortion Prob of rhyme: 0.3333333333333333\n",
      "Song: time Prob of rhyme: 0.3150684931506849\n",
      "Song: mj-elbasso Prob of rhyme: 0.3684210526315789\n",
      "Song: season Prob of rhyme: 0.3684210526315789\n",
      "Song: butter-in-the-jam Prob of rhyme: 0.3333333333333333\n",
      "Song: forget-you Prob of rhyme: 0.3181818181818182\n",
      "Song: homecoming-game Prob of rhyme: 0.34210526315789475\n",
      "Song: holding-on Prob of rhyme: 0.375\n",
      "Song: i-don-t-want-to-be-lonely Prob of rhyme: 0.3333333333333333\n",
      "Song: blackened-dove Prob of rhyme: 0.3684210526315789\n",
      "Song: dead-inside Prob of rhyme: 0.34782608695652173\n",
      "Song: her-father-and-her Prob of rhyme: 0.3225806451612903\n",
      "Song: spinning-wheel Prob of rhyme: 0.5416666666666666\n",
      "Song: little-trouble Prob of rhyme: 0.3076923076923077\n",
      "Song: my-darker-side Prob of rhyme: 0.3055555555555556\n",
      "Song: humpty-dumpty Prob of rhyme: 0.5\n",
      "Song: different-kind-of-blue Prob of rhyme: 0.4444444444444444\n",
      "Song: wherever-you-are Prob of rhyme: 0.35\n",
      "Song: caffeine-cold Prob of rhyme: 0.4375\n",
      "Song: stone-jesus Prob of rhyme: 0.42105263157894735\n",
      "Song: have-you-heard-the-news-dewey-cox-died Prob of rhyme: 0.34782608695652173\n",
      "Song: the-immortal-soul-of-mundo-cani Prob of rhyme: 0.5\n",
      "Song: four-lane-dance Prob of rhyme: 0.35714285714285715\n",
      "Song: no-far-away Prob of rhyme: 0.3023255813953488\n",
      "Song: silent-prayer Prob of rhyme: 0.36666666666666664\n",
      "Song: fall-away Prob of rhyme: 0.3333333333333333\n",
      "Song: the-boxer Prob of rhyme: 0.5714285714285714\n",
      "Song: sister Prob of rhyme: 0.30434782608695654\n",
      "Song: lonely-feeling Prob of rhyme: 0.4722222222222222\n",
      "Song: late-last-night Prob of rhyme: 0.38095238095238093\n",
      "Song: direct-hit Prob of rhyme: 0.38461538461538464\n",
      "Song: c-mon-everybody Prob of rhyme: 0.3333333333333333\n",
      "Song: rainbow-sign Prob of rhyme: 0.4\n",
      "Song: i-can-t-imagine Prob of rhyme: 0.3333333333333333\n",
      "Song: baby-britain Prob of rhyme: 0.3333333333333333\n",
      "Song: we-don-t-sleep-at-night Prob of rhyme: 0.47058823529411764\n",
      "Song: if-we-don-t-make-it-we-ll-fake-it Prob of rhyme: 0.3333333333333333\n",
      "Song: nothin-left Prob of rhyme: 0.3448275862068966\n",
      "Song: wither-away Prob of rhyme: 0.38461538461538464\n",
      "Song: power-tool Prob of rhyme: 0.3333333333333333\n",
      "Song: sophisticated-lady Prob of rhyme: 0.35714285714285715\n",
      "Song: can-t-take-my-eyes-off-of-you Prob of rhyme: 0.5\n",
      "Song: the-things-that-lovers-do Prob of rhyme: 0.3125\n",
      "Song: friends Prob of rhyme: 0.3333333333333333\n",
      "Song: the-bats-of-darkwell-lane Prob of rhyme: 0.4\n",
      "Song: keep-on-burning Prob of rhyme: 0.4339622641509434\n",
      "Song: the-thing-that-should-not-let-it-be Prob of rhyme: 0.4074074074074074\n",
      "Song: mendal-s-white-trash-laboratory Prob of rhyme: 0.3333333333333333\n",
      "Song: psychotic-reaction Prob of rhyme: 0.36363636363636365\n",
      "Song: football-fairy-story Prob of rhyme: 0.375\n",
      "Song: going-home Prob of rhyme: 0.3333333333333333\n",
      "Song: what-am-i-to-do Prob of rhyme: 0.4166666666666667\n",
      "Song: this-week Prob of rhyme: 0.375\n",
      "Song: i-m-so-cool Prob of rhyme: 0.35\n",
      "Song: got-my-mojo-working-keep-your-hands-off-of-it Prob of rhyme: 0.32558139534883723\n",
      "Song: that-s-what-you-get-for-lovin-me Prob of rhyme: 0.4375\n",
      "Song: anything-that-s-part-of-you Prob of rhyme: 0.3125\n",
      "Song: got-a-lot-o-livin-to-do Prob of rhyme: 0.34146341463414637\n",
      "Song: a-whistling-tune Prob of rhyme: 0.3076923076923077\n",
      "Song: how-can-you-lose-what-you-never-had Prob of rhyme: 0.3684210526315789\n",
      "Song: fun-in-acapulco Prob of rhyme: 0.3181818181818182\n",
      "Song: a-world-of-our-own Prob of rhyme: 0.3125\n",
      "Song: come-along Prob of rhyme: 0.4\n",
      "Song: a-little-bit-of-green Prob of rhyme: 0.34615384615384615\n",
      "Song: am-i-ready Prob of rhyme: 0.5454545454545454\n",
      "Song: i-want-you-with-me Prob of rhyme: 0.35294117647058826\n",
      "Song: cindy-cindy Prob of rhyme: 0.34615384615384615\n",
      "Song: girl-of-mine Prob of rhyme: 0.375\n",
      "Song: blue-river Prob of rhyme: 0.38461538461538464\n",
      "Song: got-my-mojo-working Prob of rhyme: 0.3333333333333333\n",
      "Song: dominic Prob of rhyme: 0.3333333333333333\n",
      "Song: i-m-gonna-sit-right-down-and-cry Prob of rhyme: 0.39285714285714285\n",
      "Song: follow-that-dream Prob of rhyme: 0.3181818181818182\n",
      "Song: hurt Prob of rhyme: 0.375\n",
      "Song: i-love-only-one-girl Prob of rhyme: 0.5294117647058824\n",
      "Song: i-was-born-about-ten-thousand-years-ago Prob of rhyme: 0.3157894736842105\n",
      "Song: hard-knocks Prob of rhyme: 0.34375\n",
      "Song: golden-coins Prob of rhyme: 0.3333333333333333\n",
      "Song: everybody-come-aboard Prob of rhyme: 0.3103448275862069\n",
      "Song: frankfort-special Prob of rhyme: 0.38461538461538464\n",
      "Song: i-need-your-love-tonight Prob of rhyme: 0.42105263157894735\n",
      "Song: good-time-charlie-s-got-the-blues Prob of rhyme: 0.30434782608695654\n",
      "Song: hell-to-pay Prob of rhyme: 0.34615384615384615\n",
      "Song: under-the-gun Prob of rhyme: 0.3333333333333333\n",
      "Song: bludsucker Prob of rhyme: 0.3333333333333333\n",
      "Song: gemini-suite Prob of rhyme: 0.3333333333333333\n",
      "Song: flight-of-the-rat Prob of rhyme: 0.36538461538461536\n",
      "Song: turn-their-backs Prob of rhyme: 0.3125\n",
      "Song: breakin-down Prob of rhyme: 0.34615384615384615\n",
      "Song: not-the-only-one Prob of rhyme: 0.3333333333333333\n",
      "Song: heartbroken-in-disrepair Prob of rhyme: 0.4166666666666667\n",
      "Song: there-s-no-here Prob of rhyme: 0.36666666666666664\n",
      "Song: plans Prob of rhyme: 0.375\n",
      "Song: it-s-me Prob of rhyme: 0.34782608695652173\n",
      "Song: how-d-you-pin-that-one-on-me Prob of rhyme: 0.37142857142857144\n",
      "Song: blowing-it Prob of rhyme: 0.3684210526315789\n",
      "Song: pond-song Prob of rhyme: 0.4\n",
      "Song: magna-cum-nada Prob of rhyme: 0.3125\n",
      "Song: its-tricky Prob of rhyme: 0.32653061224489793\n",
      "Song: mirror-me Prob of rhyme: 0.32142857142857145\n",
      "Song: no-way Prob of rhyme: 0.4166666666666667\n",
      "Song: murder Prob of rhyme: 0.3125\n",
      "Song: cruise Prob of rhyme: 0.35714285714285715\n",
      "Song: breathe-reprise Prob of rhyme: 0.4375\n",
      "Song: feel-love-thinking-of Prob of rhyme: 0.4166666666666667\n",
      "Song: evol Prob of rhyme: 0.3055555555555556\n",
      "Song: musher Prob of rhyme: 0.4375\n",
      "Song: three-flights-up Prob of rhyme: 0.3958333333333333\n",
      "Song: maybe-baby Prob of rhyme: 0.3333333333333333\n",
      "Song: sister-fatima Prob of rhyme: 0.3684210526315789\n",
      "Song: your-cheatin-heart Prob of rhyme: 0.3076923076923077\n",
      "Song: miss-american-pie Prob of rhyme: 0.344\n",
      "Song: castles-in-the-air Prob of rhyme: 0.39285714285714285\n",
      "Song: g-o-d-good-old-days Prob of rhyme: 0.42105263157894735\n",
      "Song: san-francisco-girls Prob of rhyme: 0.5\n",
      "Song: i-just-wanna-stand-next-to-you Prob of rhyme: 0.375\n",
      "Song: whatever-it-is-i-don-t-care Prob of rhyme: 0.3333333333333333\n",
      "Song: skinhead-boneheads Prob of rhyme: 0.4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-146134d50870>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpronouncing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrhymes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m                 \u001b[0mnum_rhymes\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnum_rhymes\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m.3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "loops = 0\n",
    "\n",
    "with open('english_rock.csv', encoding='utf8') as csv_file:\n",
    "    csv_reader = csv.DictReader(csv_file)\n",
    "    for row in csv_reader:\n",
    "        lines = row['lyrics'].split('\\n')\n",
    "        num_rhymes = 0\n",
    "        for i in range(len(lines) - 1):\n",
    "            if not lines[i].split() or not lines[i+1].split():\n",
    "                continue\n",
    "            if lines[i].split()[-1] in pronouncing.rhymes(lines[i+1].split()[-1]):\n",
    "                num_rhymes += 1\n",
    "        if num_rhymes / len(lines) > .3:\n",
    "            print(f'Song: {row[\"song\"]} Prob of rhyme: {num_rhymes / len(lines)}')\n",
    "        loops += 1\n",
    "        if loops > 100:\n",
    "            continue\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KtZVXKrla515"
   },
   "outputs": [],
   "source": [
    "line_choices = [[lineB for lineB in lines if lineB != lineA] for lineA in lines]\n",
    "short_lines = lines[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 107
    },
    "colab_type": "code",
    "id": "xJQj50shcdNC",
    "outputId": "b90c6ce8-9ccd-4884-f160-eb49756fbd81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.07894736842105263\n",
      "[\"A lot of cats are hatin', slandering makin' bad statements\", 'Mad cause they sit on their ass just stagnating', \"Always vacillatin', now classmates I graduated with\", \"Are wonderin' how the stupidest kid up in the class made it\", \"Sick landscapin' and jammin' down in my mans basement\", 'Getting restraints and complaints from mad neighbors', 'Now prejudice bigots say I sound just like them damn #%#', \"Them pair of lenses ain't repairin' their impaired vision\", \"I'm on a mission escaping my own prison\", \"Inflicting more pain then you're givin' see I'm my own victim\", \"I can't believe I let you take up my time\", \"Take up space in mind, give it here, I'm takin' what's mine\", '(Chrous)', 'The only ounce of power that I have', 'Is what I do with now', 'And how I let the hours pass', \"I dont' know how long I'm gonna last\", \"So I can't let ya snatch the powder out my hourglass\", \"Everyday that I'm awake I face the angel of death\", 'He may be taken my breath, so they can lay me to rest', \"And by now my inner state's the only place that I rep\", 'The way that I dress is just another way to express', 'We know that some day everybody we see will be dead and rotten', 'Long forgotten, we oughta keep this for a normal topic', 'Because we all get caught up in all the drama', \"But what's the gossip gonna mean, when me and you are goners\", 'See I never did audition for a part in this play', \"I know that some day I'll accidentally fall in my grave\", 'So I can really give a shit about what all of ya say', \"According to me is how I'm spending all of my days\", '(Chorus)', \"The world will keep turnin', the inferno will keep burnin'\", \"But it's affirmative my life on Earth is impermanent\", \"And since I'm visiting and my minutes here are limited\", \"I ain't havin' or doin' shit if I ain't feelin' it\", \"I'll lend a hand to a hurt pedestrian and I will help a friend\", \"In any way that I can, but I can't let man get up in the way of my plans\", \"Make me stray from my path, I can't be takin' that chance\", '(Chorus)']\n",
      "[\"Are wonderin' how the stupidest kid up in the class made it\", \"A lot of cats are hatin', slandering makin' bad statements\", \"So I can't let ya snatch the powder out my hourglass\", \"I ain't havin' or doin' shit if I ain't feelin' it\", \"I'm on a mission escaping my own prison\", \"Sick landscapin' and jammin' down in my mans basement\", \"And by now my inner state's the only place that I rep\", \"A lot of cats are hatin', slandering makin' bad statements\", 'Now prejudice bigots say I sound just like them damn #%#', 'See I never did audition for a part in this play', \"In any way that I can, but I can't let man get up in the way of my plans\", 'Long forgotten, we oughta keep this for a normal topic', \"But what's the gossip gonna mean, when me and you are goners\", 'So I can really give a shit about what all of ya say', \"And since I'm visiting and my minutes here are limited\", \"According to me is how I'm spending all of my days\", 'So I can really give a shit about what all of ya say', \"In any way that I can, but I can't let man get up in the way of my plans\", \"According to me is how I'm spending all of my days\", \"Take up space in mind, give it here, I'm takin' what's mine\", \"Sick landscapin' and jammin' down in my mans basement\", 'We know that some day everybody we see will be dead and rotten', \"In any way that I can, but I can't let man get up in the way of my plans\", \"And since I'm visiting and my minutes here are limited\", \"Everyday that I'm awake I face the angel of death\", 'See I never did audition for a part in this play', 'Now prejudice bigots say I sound just like them damn #%#', 'The only ounce of power that I have', \"In any way that I can, but I can't let man get up in the way of my plans\", \"Sick landscapin' and jammin' down in my mans basement\", 'Because we all get caught up in all the drama', \"Always vacillatin', now classmates I graduated with\", \"A lot of cats are hatin', slandering makin' bad statements\", \"Always vacillatin', now classmates I graduated with\", \"Sick landscapin' and jammin' down in my mans basement\", \"In any way that I can, but I can't let man get up in the way of my plans\", \"So I can't let ya snatch the powder out my hourglass\", \"Take up space in mind, give it here, I'm takin' what's mine\"]\n",
      "['Mad cause they sit on their ass just stagnating', \"Always vacillatin', now classmates I graduated with\", \"Are wonderin' how the stupidest kid up in the class made it\", \"Sick landscapin' and jammin' down in my mans basement\", 'Getting restraints and complaints from mad neighbors', 'Now prejudice bigots say I sound just like them damn #%#', \"Them pair of lenses ain't repairin' their impaired vision\", \"I'm on a mission escaping my own prison\", \"Inflicting more pain then you're givin' see I'm my own victim\", \"I can't believe I let you take up my time\", \"Take up space in mind, give it here, I'm takin' what's mine\", '(Chrous)', 'The only ounce of power that I have', 'Is what I do with now', 'And how I let the hours pass', \"I dont' know how long I'm gonna last\", \"So I can't let ya snatch the powder out my hourglass\", \"Everyday that I'm awake I face the angel of death\", 'He may be taken my breath, so they can lay me to rest', \"And by now my inner state's the only place that I rep\", 'The way that I dress is just another way to express', 'We know that some day everybody we see will be dead and rotten', 'Long forgotten, we oughta keep this for a normal topic', 'Because we all get caught up in all the drama', \"But what's the gossip gonna mean, when me and you are goners\", 'See I never did audition for a part in this play', \"I know that some day I'll accidentally fall in my grave\", 'So I can really give a shit about what all of ya say', \"According to me is how I'm spending all of my days\", '(Chorus)', \"The world will keep turnin', the inferno will keep burnin'\", \"But it's affirmative my life on Earth is impermanent\", \"And since I'm visiting and my minutes here are limited\", \"I ain't havin' or doin' shit if I ain't feelin' it\", \"I'll lend a hand to a hurt pedestrian and I will help a friend\", \"In any way that I can, but I can't let man get up in the way of my plans\", \"Make me stray from my path, I can't be takin' that chance\", '(Chorus)']\n"
     ]
    }
   ],
   "source": [
    "next_lines = []\n",
    "next_lines_gold = lines[1:]\n",
    "for i in range(len(lines) - 1):\n",
    "    next_line = predict_next_sentence(lines[i], line_choices[i], tokenizer, model)\n",
    "    next_lines.append(next_line)\n",
    "\n",
    "num_right = 0\n",
    "num_total = 0\n",
    "for pred, gold in zip(next_lines, next_lines_gold):\n",
    "    num_total += 1\n",
    "    if pred == gold:\n",
    "        num_right += 1\n",
    "\n",
    "print(f'Accuracy: {num_right / num_total}')\n",
    "print(lines)\n",
    "print(next_lines)\n",
    "print(next_lines_gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UMqkSykzdVNF"
   },
   "outputs": [],
   "source": [
    "a = torch.LongTensor([[1,2],[3,2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FHYwTyVo--Ve"
   },
   "outputs": [],
   "source": [
    "a[:, 0] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "xpqnlxn-_HaI",
    "outputId": "7d49fe60-77e0-461f-c668-5ca580b6b8ad"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 2],\n",
       "        [4, 2]])"
      ]
     },
     "execution_count": 30,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MJS8CU_D_O7F"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "predict_next_sentence.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
