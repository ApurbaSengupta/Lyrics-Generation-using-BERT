{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rhymings.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "KYHRcp62BLqS",
        "colab_type": "code",
        "outputId": "a5654fd2-6a4f-4821-b725-8135f8df9db9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install pytorch_pretrained_bert"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_pretrained_bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 9.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2018.1.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.16.3)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.9.139)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.28.1)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.1.0)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.2.0)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.139 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.12.139)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.2)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.8)\n",
            "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.139->boto3->pytorch_pretrained_bert) (0.14)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.139->boto3->pytorch_pretrained_bert) (2.5.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.139->boto3->pytorch_pretrained_bert) (1.12.0)\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "U2_KKFQqZ_3d",
        "colab_type": "code",
        "outputId": "bfc8ea77-9f91-4f79-b325-110758dfeca7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install pronouncing"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pronouncing\n",
            "  Downloading https://files.pythonhosted.org/packages/7f/c6/9dc74a3ddca71c492e224116b6654592bfe5717b4a78582e4d9c3345d153/pronouncing-0.2.0.tar.gz\n",
            "Collecting cmudict>=0.4.0 (from pronouncing)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/bc/606843d7cfe4d82f5a21fc46d1ae8e364ac20c57e68d1ec4190bce4f2734/cmudict-0.4.2-py2.py3-none-any.whl (938kB)\n",
            "\u001b[K     |████████████████████████████████| 942kB 15.6MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pronouncing\n",
            "  Building wheel for pronouncing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/fd/e8/fb1a226f707c7e20dbed4c43f81b819d279ffd3b0e2f06ee13\n",
            "Successfully built pronouncing\n",
            "Installing collected packages: cmudict, pronouncing\n",
            "Successfully installed cmudict-0.4.2 pronouncing-0.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Q0KZMlB1JnpJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.distributions import Categorical\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertForMaskedLM, BertForNextSentencePrediction\n",
        "import pronouncing\n",
        "from itertools import chain\n",
        "import string\n",
        "import csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nbVGLH4MMsPY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "6b35b3de-2c1f-40d9-8d40-9c66d5ee8587"
      },
      "cell_type": "code",
      "source": [
        "# mount Google Drive root\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zc6gw-GC1RK-",
        "colab_type": "code",
        "outputId": "86207fec-9584-462b-cc80-604d40354cda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "\"\"\" Try to generate from BERT \"\"\"\n",
        "\n",
        "def preprocess(tokens, tokenizer, device):\n",
        "    \"\"\" Preprocess the lyrics by tokenizing and converting to tensor \"\"\"\n",
        "    \n",
        "    tok_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "    tok_tensor = torch.tensor([tok_ids])\n",
        "    tok_tensor = tok_tensor.to(device)\n",
        "    return tok_tensor\n",
        "\n",
        "  \n",
        "def get_seed_sent(toks1, toks2, tokenizer):\n",
        "    \"\"\" Get initial sentence to decode from, possible with masks \"\"\"\n",
        "\n",
        "    mask_ids = []\n",
        "\n",
        "    # get total lyric tokens and [MASK] indices\n",
        "    toks = toks1 + toks2\n",
        "    for i, tok in enumerate(toks):\n",
        "        if tok == \"[MASK]\":\n",
        "            mask_ids.append(i)\n",
        "            \n",
        "    # get lyric segments\n",
        "    seg = [0] * len(toks1) + [1] * len(toks2)\n",
        "    \n",
        "    # convert segments to tensors\n",
        "    seg_tensor = torch.tensor([seg])\n",
        "    \n",
        "    return toks, seg_tensor, mask_ids\n",
        "\n",
        "  \n",
        "def load_masked_lang_model(version):\n",
        "    \"\"\" Load BERT MLM \"\"\"\n",
        "    model = BertForMaskedLM.from_pretrained(version)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "\n",
        "def load_next_sent_pred_model(version):\n",
        "    \"\"\" Load BERT next sentence prediction model \"\"\"\n",
        "    model = BertForNextSentencePrediction.from_pretrained(version)\n",
        "    model.eval()\n",
        "    return model\n",
        "  \n",
        "  \n",
        "def predict(model, tokenizer, tok_tensor, seg_tensor, how_select=\"argmax\"):\n",
        "    \"\"\" Get model predictions and convert back to tokens \"\"\"\n",
        "    preds = model(tok_tensor, seg_tensor)\n",
        "    \n",
        "    # select random if \"sample\"\n",
        "    if how_select == \"sample\":\n",
        "        dist = Categorical(logits=F.log_softmax(preds[0], dim=-1))\n",
        "        pred_idxs = dist.sample().tolist()\n",
        "        \n",
        "    # select top-3 if \"topk\"\n",
        "    elif how_select == \"topk\":\n",
        "        kth_vals, kth_idx = F.log_softmax(preds[0], dim=-1).topk(3, dim=-1)\n",
        "        dist = Categorical(logits=kth_vals)\n",
        "        pred_idxs = kth_idx.gather(dim=1, index=dist.sample().unsqueeze(-1)).squeeze(-1).tolist()\n",
        "        \n",
        "    # select best possible if \"argmax\"\n",
        "    elif how_select == \"argmax\":\n",
        "        pred_idxs = preds.argmax(dim=-1).tolist()[0]\n",
        "        \n",
        "    # if none of the above, raise error\n",
        "    else:\n",
        "        raise NotImplementedError(\"Prediction procedure %s not found!\" % how_select)\n",
        "    \n",
        "    # return predicted [MASK] tags\n",
        "    pred_toks = tokenizer.convert_ids_to_tokens(pred_idxs)\n",
        "    return pred_toks\n",
        "\n",
        "  \n",
        "def masked_decoding(toks, device, seg_tensor, masks, model, tokenizer, selection_strategy):\n",
        "    \"\"\" Decode from model by replacing masks \"\"\"\n",
        "    for step_n, mask_id in enumerate(masks):\n",
        "        tok_tensor = preprocess(toks, tokenizer, device)\n",
        "        pred_toks = predict(model, tokenizer, tok_tensor, seg_tensor, selection_strategy)\n",
        "        toks[mask_id] = pred_toks[mask_id]\n",
        "    return toks\n",
        "\n",
        "  \n",
        "def best_follows(text1_tokens, text2_tokens, tokenizer, model, device, k=1):\n",
        "    \"\"\" Return k best next sentence predictions \"\"\"\n",
        "    \n",
        "    # get seed lyric tokens and segment and attention lists\n",
        "    text1_token_ids = tokenizer.convert_tokens_to_ids(text1_tokens)\n",
        "    text1_seg = [0] * len(text1_token_ids)\n",
        "    text1_attention = [1] * len(text1_token_ids)\n",
        "    \n",
        "    tok_ids = []\n",
        "    tok_segs = []\n",
        "    tok_attentions = []\n",
        "    \n",
        "    # get target lyric tokens and segment and attention lists\n",
        "    text2_token_ids = []\n",
        "    for text2_token in text2_tokens:\n",
        "        text2_token_ids.append(tokenizer.convert_tokens_to_ids(text2_token))\n",
        "    \n",
        "    max_text2_length = max(len(text2_token_id) for text2_token_id in text2_token_ids)\n",
        "    \n",
        "    # get total lyric tokens and segment and attention lists\n",
        "    for text2_token_id in text2_token_ids:\n",
        "        padding_size = max_text2_length - len(text2_token_id)\n",
        "        padded_text2_id = text2_token_id + [0] * padding_size\n",
        "        padded_text2_seg = [1] * max_text2_length\n",
        "        padded_text2_attention = [1] * len(text2_token_id) + [0] * padding_size\n",
        "        \n",
        "        tok_ids.append(text1_token_ids + padded_text2_id)\n",
        "        tok_segs.append(text1_seg + padded_text2_seg)\n",
        "        tok_attentions.append(text1_attention + padded_text2_attention)\n",
        "    \n",
        "    # convert tokens and segment and attention lists to tensors\n",
        "    tok_ids_tensor = torch.LongTensor(tok_ids)\n",
        "    tok_segs_tensor = torch.LongTensor(tok_segs)\n",
        "    tok_attention_tensor = torch.LongTensor(tok_attentions)\n",
        "    \n",
        "    # transport to device\n",
        "    tok_ids_tensor = tok_ids_tensor.to(device)\n",
        "    tok_segs_tensor = tok_segs_tensor.to(device)\n",
        "    tok_attention_tensor = tok_attention_tensor.to(device)\n",
        "\n",
        "    # get is next or not next predictions\n",
        "    seq_relationship_logits = model(tok_ids_tensor, tok_segs_tensor, tok_attention_tensor)\n",
        "    \n",
        "    # get the top-3/top-1 predictions and return the respective tokens\n",
        "    _, idxs = torch.topk(seq_relationship_logits[:,0], k)\n",
        "    \n",
        "    return [text2_tokens[i] for i in idxs.tolist()]\n",
        "\n",
        "                \n",
        "@torch.no_grad()  \n",
        "def main():\n",
        "    \n",
        "    # set device : use CUDA backend if GPU available\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    \n",
        "    # get BERT tokenizer and pre-trained models\n",
        "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "    masked_lang_model = load_masked_lang_model('bert-base-uncased')\n",
        "    next_sent_pred_model = load_next_sent_pred_model('bert-base-uncased')\n",
        "    \n",
        "    # transport model to device\n",
        "    masked_lang_model = masked_lang_model.to(device)\n",
        "    next_sent_pred_model = next_sent_pred_model.to(device)\n",
        "    \n",
        "    # get data\n",
        "    five_pairs = []\n",
        "    with open(\"gdrive/My Drive/CIS_530_Project/data/test_rock.csv\", encoding='utf8') as csv_file:\n",
        "        csv_reader = csv.DictReader(csv_file)\n",
        "        for row in csv_reader:\n",
        "            lines = row['lyrics'].split('\\n')\n",
        "            for i in range(0,len(lines)-4,5):\n",
        "                five_pairs.append([lines[i].strip(), lines[i + 1].strip(), lines[i + 2].strip(), lines[i + 3].strip(), lines[i + 4].strip()])\n",
        "    cnt = 0\n",
        "    \n",
        "    # predictions for each pair of 5 lyrics\n",
        "    for five_list in five_pairs:\n",
        "        \n",
        "        \"\"\" Pre-process texts to get seed text and target texts \"\"\"\n",
        "        \n",
        "        text = (\"\\n\").join(five_list)\n",
        "        \n",
        "        # put [CLS] and [SEP] tags for lyric 'beginning' and 'end' annotation\n",
        "        text = text.replace(\"\\n\",\" [SEP] \")\n",
        "        text = \"[CLS] \" + text\n",
        "        \n",
        "        # add/keep punctuation at end of every other lyric\n",
        "        text_split = text.split(\" [SEP] \")\n",
        "        for i in range(len(text_split)):\n",
        "            if i%2 != 0:\n",
        "                if text_split[i][-1] not in string.punctuation:\n",
        "                    text_split[i] = text_split[i] + \".\"\n",
        "        \n",
        "        # seed length\n",
        "        text1_len = 3\n",
        "        \n",
        "        # get seed text tokens\n",
        "        text1 = (\" [SEP] \").join(text_split[:text1_len]) + \" [SEP]\"\n",
        "        toks1 = tokenizer.tokenize(text1)\n",
        "\n",
        "        text2s = text_split[text1_len:]\n",
        "        text2s_true = text2s.copy()\n",
        "        \n",
        "        # mask desired target lyric with [MASK] and [RHYME] tags\n",
        "        for i in range(len(text2s)):\n",
        "            if i%2 == 0:\n",
        "                text2s[i] = \"[MASK] \" * (len(text2s[i].split()) - 1) + \" [RHYME]\" + \". [SEP]\"\n",
        "                if text2s_true[i][-1] not in string.punctuation:\n",
        "                    text2s_true[i] = text2s_true[i] + \". [SEP]\"\n",
        "                else:\n",
        "                    text2s_true[i] = text2s_true[i] + \" [SEP]\"\n",
        "            else:\n",
        "                text2s[i] = text2s[i] + \" [SEP]\"\n",
        "                text2s_true[i] = text2s_true[i] + \" [SEP]\"\n",
        "\n",
        "        text2 = (\" \").join(text2s)\n",
        "        \n",
        "        text2_true = (\" \").join(text2s_true)\n",
        "        toks2_true = tokenizer.tokenize(text2_true)\n",
        "        \n",
        "        # get target word to rhyme\n",
        "        last_focus = text1.split(\" \")[-2]\n",
        "        if \"-\" in last_focus:\n",
        "            last_focus = last_focus.split(\"-\")[-1]\n",
        "        \n",
        "        # get list of rhyming words based on last phone sound and number of syllables\n",
        "        if len(pronouncing.phones_for_word(last_focus)) > 0:\n",
        "          \n",
        "          # get phone sound\n",
        "          phones = pronouncing.phones_for_word(last_focus)[0]\n",
        "          # get number of syllables\n",
        "          syllables = pronouncing.syllable_count(phones)\n",
        "          # get list of all rhymings\n",
        "          rhymings = pronouncing.rhymes(last_focus)\n",
        "          \n",
        "          # filter the rhymings based on last phone sound and number of syllables\n",
        "          rhymings_updated = [rhyming for rhyming in rhymings if pronouncing.phones_for_word(rhyming)[0].split(\" \")[-1]==phones.split(\" \")[-1] and pronouncing.syllable_count(pronouncing.phones_for_word(rhyming)[0])==syllables]\n",
        "          \n",
        "          # use the target word in case no rhyming found\n",
        "          if len(rhymings_updated) == 0:\n",
        "            rhymings_updated = [last_focus]\n",
        "        \n",
        "        # use the target word if no phones found\n",
        "        else:\n",
        "          rhymings_updated = [last_focus]\n",
        "        \n",
        "        outputs = []\n",
        "        \n",
        "        # get all possible rhyming sequences based on the BERT masked LM\n",
        "        for rhyming in rhymings_updated:\n",
        "            \n",
        "            # replace [RHYME] tag with the rhyming(s) found above\n",
        "            text2_r = text2.replace(\"[RHYME]\",rhyming)\n",
        "            \n",
        "            # get target lyric tokens\n",
        "            toks2 = tokenizer.tokenize(text2_r)\n",
        "            \n",
        "            # get lyric tokens, segment tensors and mask indices\n",
        "            toks, seg_tensor, mask_ids = get_seed_sent(toks1, toks2, tokenizer)\n",
        "            seg_tensor = seg_tensor.to(device)\n",
        "            \n",
        "            # get [MASK] predictions\n",
        "            pred_toks = masked_decoding(toks, device, seg_tensor, mask_ids, masked_lang_model, tokenizer, \"argmax\")\n",
        "            \n",
        "            # get predicted lyric\n",
        "            outputs.append(pred_toks[len(toks1):])\n",
        "        \n",
        "        # get top-3/top-1 best sequence as predicted by the BERT next sentence prediction model\n",
        "        if len(rhymings_updated) >= 3:\n",
        "            outz = best_follows(toks1, outputs, tokenizer, next_sent_pred_model, device, k=3)\n",
        "        else:\n",
        "            outz = best_follows(toks1, outputs, tokenizer, next_sent_pred_model, device, k=1)\n",
        "        \n",
        "        with open(\"gdrive/My Drive/CIS_530_Project/test_top_preds_file.txt\", \"a\") as file1:\n",
        "            file1.write(\"\\n Top-\"+str(len(outz))+\" predictions: \"+str(outz)+\"\\n\")\n",
        "        \n",
        "        # print the best possible lyric\n",
        "        toks_pred = toks1 + outz[0]\n",
        "        \n",
        "        with open(\"gdrive/My Drive/CIS_530_Project/test_pred_file.txt\", \"a\") as file2:\n",
        "            file2.write(\"\\n\"+(\" \").join(toks_pred)+\"\\n\")\n",
        "        \n",
        "        toks_gold = toks1 + toks2_true\n",
        "        \n",
        "        with open(\"gdrive/My Drive/CIS_530_Project/test_gold_file.txt\", \"a\") as file3:\n",
        "            file3.write(\"\\n\"+(\" \").join(toks_gold)+\"\\n\")\n",
        "        \n",
        "        # clear cache\n",
        "        torch.cuda.empty_cache()\n",
        "        \n",
        "        cnt += 1\n",
        "        \n",
        "        if cnt%5000 == 0:\n",
        "            \n",
        "            print(\"Processed %s 5-pairs\" %cnt)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 919914.59B/s]\n",
            "100%|██████████| 407873900/407873900 [00:14<00:00, 27307492.24B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "arY_9H2IlXSu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "def loadData(name):\n",
        "    data = []\n",
        "    with open(name) as file:\n",
        "        for line in file:\n",
        "            if(line == '\\n'):\n",
        "              continue\n",
        "#             pdb.set_trace()\n",
        "            data.append(line.split(\" [SEP] \")[-2])\n",
        "\n",
        "    return data\n",
        "\n",
        "def bleuScore(gold, pred):\n",
        "    cumulativeBlue, totalSentences = 0, len(gold)\n",
        "\n",
        "    for i in range(len(gold)):\n",
        "       \n",
        "        reference = [gold[i].split(' ')]\n",
        "        candidate = pred[i].split(' ') \n",
        "        cumulativeBlue += sentence_bleu(reference, candidate, weights=(.334, 0.333, 0.333, 0))\n",
        "\n",
        "    return cumulativeBlue / totalSentences  \n",
        "\n",
        "def accuracy(gold, pred):\n",
        "    num_correct, num_total = 0, 0\n",
        "    for i in range(len(gold)):\n",
        "        if gold[i] == pred[i]:\n",
        "            num_correct += 1\n",
        "        num_total += 1\n",
        "\n",
        "    accuracy = num_correct / num_total\n",
        "\n",
        "    return accuracy\n",
        "  \n",
        "\n",
        "if __name__ == '__main__':\n",
        "  gold = loadData(\"gdrive/My Drive/courseWorks/Lyrics/preds/test_gold_file.txt\")\n",
        "  pred = loadData(\"gdrive/My Drive/courseWorks/Lyrics/preds/test_pred_file.txt\")\n",
        "  print(f'Accuracy: {accuracy(gold, pred):.2f}')\n",
        "  print(f'BLEU score: {bleuScore(gold, pred):.2f}')\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}